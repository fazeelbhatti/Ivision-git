{
  "name": "Ivision-git",
  "tagline": "University face detection and recognition project.",
  "body": "\t# IVISION Face Detection and Recognition in videos\r\nNote:\r\nThe project utilises the following libraries and dependencies.\r\n-ipython\r\n-python\r\n-sickit-learn\r\n-sickit-image\r\n-opencv (preferred 3.0.0)\r\n-numpy\r\n-webbrowser\r\n-Running php server for web interfaces\r\n-other dependencies are within this package\r\n\r\nThe working of the project is quite simple and straightforward. The work is done in easy to understand and excecute \"iphython notebooks\" using python.\r\n\r\nAll the code is contained in the main notebook; \"Testfile.ipynb\", which itself has been commented for better understandability.\r\n\r\nYou will need a Video to feed to the code for any kind of testing or training. Enter name of your video in the first block of the Testing or Training portion.\r\nNote: Project is done for a classroom environment to mark attendance of students. Videos used are of classrooms.\r\n\r\nTraining Data is stored in the \"TrainData\" directory with currently manuaaly labelled images.\r\nTest Data will be stored in the \"TestData directory of the project.\r\n\r\nIf you want to create your own Train Data open up the notebook and run the blocks sequentially till you see the \"Video Capture for Test Data\" heading.\r\nThis portion will extract faces from the video which you will have to label manually using the web interface(accessed from the code itself) for the purpose of \r\ngetting a Training Dataset.\r\n\r\nIf you want to predict results on a video start with the heading of \"Train Classifier\" and execute the blocks seqeuntially till the end to get a prediction.\r\n \r\nThe notebook itself has been commented and provided headings for better understanding.    \r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}