{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IVision\n",
    "   Intelligent Attendace System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from Videoprocessing import *\n",
    "from Classifier import *\n",
    "#import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage import data, color, exposure\n",
    "from sklearn.svm import LinearSVC\n",
    "import argparse\n",
    "import cv2\n",
    "import os.path\n",
    "import numpy as np\n",
    "import webbrowser  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vid=Videoprocess()\n",
    "#vid.Extractfaces()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Video Capture For Tagging+Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#This captures frames from the given video and individually detects \n",
    "#and stores faces from those frames to the \"faces\" directory\n",
    "cap = cv2.VideoCapture('IMG_4100.MOV')\n",
    "face_cascade = cv2.CascadeClassifier('C:\\opencv\\sources\\data\\haarcascades\\haarcascade_frontalface_default.xml')\n",
    "print cap.grab()\n",
    "i=0\n",
    "j=0\n",
    "ret, frame = cap.read()\n",
    "while(ret):\n",
    "    # Capture frame-by-frame\n",
    "    #print j\n",
    "    ret, frame = cap.read()\n",
    "        # Our operations on the frame come here\n",
    "    if j%10==0:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.2, )\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "            cv2.imwrite('faces/Testimg'+str(i)+'.png',frame[y:y+h,x:x+w])\n",
    "            i=i+1\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame',frame)\n",
    "        j+=1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        j+=1\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n",
      "130\n",
      "(130L, 2500L)\n"
     ]
    }
   ],
   "source": [
    "#converts all the faces to a standard size of 50x50\n",
    "#overwrites in the \"faces\" directory\n",
    "num_files = sum(os.path.isfile(os.path.join('faces', f)) for f in os.listdir('faces'))\n",
    "print num_files\n",
    "t=[]\n",
    "for i in range(0,num_files-1):\n",
    "    img=cv2.imread('faces/Testimg' +str(i)+'.png',0)\n",
    "    simg3=cv2.resize(img,(50,50))\n",
    "    t.append(simg3.reshape(2500))\n",
    "    #simg3=cv2.resize(img,(100,100))\n",
    "    cv2.imwrite('faces/Testimg'+str(i)+'.png',simg3)    \n",
    "print len(t)   \n",
    "data=np.array(t)\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n"
     ]
    }
   ],
   "source": [
    "num_files = sum(os.path.isfile(os.path.join('faces', f)) for f in os.listdir('faces'))\n",
    "print num_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130L, 2500L)\n",
      "(130L, 2500L)\n",
      "[  50.3752064     0.           41.1193919    28.7832497    56.55263351\n",
      "   12.0489158    43.89272096   31.40106975   56.67878323   56.99790389\n",
      "   12.09283408   44.0579369    35.74567904   58.66778572   50.08937415\n",
      "   11.39528209   41.4377925    33.3734993    51.57564308   18.31699192\n",
      "   45.75014092   35.89032667   69.02419723   51.81013837   40.40430115\n",
      "   51.82007217   18.90811215   48.76528075   32.23888297   70.85495762\n",
      "   46.86977375   31.76763579   47.70053993   17.48990012   45.10315361\n",
      "   69.47566955   48.39918728   55.87745669   48.75337913   25.35036901\n",
      "   44.91870699   36.14779373   53.42412611   68.58149379   51.31196898\n",
      "   63.89966186   63.59077611   55.34892298   35.97847768   47.58497111\n",
      "   65.90758257   40.99816295   54.40752482   37.30682454   52.44397387\n",
      "   69.71261412   49.06685621   45.87501136   37.43200476   43.58311144\n",
      "   46.88114647   55.56294661   48.45652043   54.88464459   40.07642756\n",
      "   53.86983746   68.37302342   37.37018621   50.40681898   49.34629322\n",
      "   53.67966785   50.1053976    44.09578732   34.89718101   49.73709703\n",
      "   66.2348879    51.3258541    31.46411958   49.91915579   42.61140684\n",
      "   55.33152549   45.71677263   46.58578896   41.90392961   62.85499702\n",
      "   61.25138502   52.97526241   33.16203626   50.04514619   51.17095277\n",
      "   52.08162032   47.12991824   45.81823889   32.56357268   43.24918783\n",
      "   53.92222327   43.40291355   51.4148706    47.15559562   44.66988378\n",
      "   93.32407663   44.03450204   32.63266228   45.68657557   50.09308123\n",
      "   46.55627065   85.2035174    48.73071093   45.24396467   49.24247388\n",
      "  111.76835594   23.68262867   44.24327556   53.25685482   44.06767333\n",
      "   47.48153076   48.68285646  113.62506899   23.39518589   46.01957397\n",
      "   51.28382534   46.28759379   49.79974586   43.60934391  102.3021539\n",
      "   46.91838667   51.13789753   41.96104921   42.5548169    44.20594182]\n"
     ]
    }
   ],
   "source": [
    "#Applies HOG on all faces\n",
    "Train=[]\n",
    "Test=[]\n",
    "#hist=np.array(hist)\n",
    "for i in range(0,num_files-1):\n",
    "    image=cv2.imread('faces/Testimg' +str(i)+'.png',0)\n",
    "    fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualise=True)\n",
    "    hog_image=np.array(hog_image)\n",
    "    hog_image=hog_image.ravel()\n",
    "    Train.append(hog_image)\n",
    "    Test.append(hog_image)\n",
    "a=np.array(Train)\n",
    "b=np.array(Test)\n",
    "print a.shape\n",
    "print b.shape\n",
    "\n",
    "\n",
    "#for i in range(0,num_files-1):\n",
    "#    image=cv2.imread('UniqueFaces/Testimg' +str(i)+'.png',0)\n",
    "#    fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualise=True)\n",
    "#    Test.append(hog_image[:])   \n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "dists=cdist(Test,Train)\n",
    "print dists[1]\n",
    "if num_files>=175:\n",
    "    k=12\n",
    "else:\n",
    "    k=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  23.   14.   18.   30.]\n",
      " [  15.    5.   10.   33.]\n",
      " [  11.   16.    6.   20.]\n",
      " [   7.   17.  102.   87.]\n",
      " [   9.   18.   14.   57.]\n",
      " [  10.    1.   15.   19.]\n",
      " [  16.    2.   20.   11.]\n",
      " [  17.   12.   28.    3.]\n",
      " [  13.   22.   84.   29.]\n",
      " [   4.   14.   18.   57.]\n",
      " [   5.   15.    1.   26.]\n",
      " [   2.   20.    6.   16.]\n",
      " [  17.    7.   28.   21.]\n",
      " [  84.    8.   22.   29.]\n",
      " [  30.   60.   57.    0.]\n",
      " [  10.    1.   19.    5.]\n",
      " [   6.    2.   20.   11.]\n",
      " [  12.    7.   28.   77.]\n",
      " [  23.   14.   57.    0.]\n",
      " [  15.   26.   10.    1.]\n",
      " [  11.   16.    6.    2.]\n",
      " [  28.   17.   87.  102.]\n",
      " [  29.   35.   84.   13.]\n",
      " [  18.    0.   57.   14.]\n",
      " [  58.   83.   92.  103.]\n",
      " [  97.   80.  120.   70.]\n",
      " [  19.   15.   10.    1.]\n",
      " [  20.   76.   32.   11.]\n",
      " [  77.   17.   31.    7.]\n",
      " [  22.   35.   84.   43.]\n",
      " [  14.   57.   60.   36.]\n",
      " [  77.   28.   87.   41.]\n",
      " [  74.   42.   56.   27.]\n",
      " [   1.   15.   39.   19.]\n",
      " [  97.   38.   89.   80.]\n",
      " [  43.   66.   75.   29.]\n",
      " [  57.   30.   60.   23.]\n",
      " [  61.   52.   69.   78.]\n",
      " [  54.   34.   97.   63.]\n",
      " [  26.   33.   19.   15.]\n",
      " [ 112.   98.  103.   92.]\n",
      " [  51.   67.   31.   77.]\n",
      " [  56.   32.   65.   76.]\n",
      " [  66.   35.   55.   75.]\n",
      " [  36.   57.   68.   16.]\n",
      " [  42.   56.   65.   76.]\n",
      " [  52.   37.   61.   88.]\n",
      " [  54.   70.   38.   63.]\n",
      " [  53.   64.   83.   72.]\n",
      " [  51.   41.   67.   73.]\n",
      " [  66.   55.   43.   35.]\n",
      " [  41.   67.   73.   87.]\n",
      " [  37.   61.   69.   88.]\n",
      " [  48.   64.   83.   72.]\n",
      " [  38.   63.   97.   34.]\n",
      " [  66.   43.   35.   75.]\n",
      " [  42.   76.   74.   32.]\n",
      " [  60.   30.   36.   14.]\n",
      " [  24.   83.   64.   72.]\n",
      " [  82.   71.  129.   96.]\n",
      " [  57.   30.   14.   36.]\n",
      " [  37.   69.   52.   88.]\n",
      " [  71.   96.   82.  129.]\n",
      " [  89.   54.   80.   97.]\n",
      " [  83.   72.   53.   48.]\n",
      " [  42.   32.   56.   76.]\n",
      " [  55.   43.   35.   75.]\n",
      " [  73.   87.   51.   41.]\n",
      " [  60.   57.   36.   30.]\n",
      " [  61.   37.   88.   52.]\n",
      " [  97.   54.   25.   47.]\n",
      " [  82.   62.   91.   59.]\n",
      " [  83.  103.   98.   92.]\n",
      " [  87.   67.  102.   93.]\n",
      " [  32.   56.   76.   42.]\n",
      " [  66.   43.   35.   55.]\n",
      " [  56.   74.   27.   32.]\n",
      " [  31.   87.   28.   93.]\n",
      " [  37.   69.   61.   88.]\n",
      " [  94.  101.  127.  108.]\n",
      " [  89.   97.  120.   63.]\n",
      " [ 128.   99.  105.   83.]\n",
      " [  71.   91.   59.   96.]\n",
      " [  72.   92.   64.  103.]\n",
      " [  13.   29.   75.   55.]\n",
      " [  44.   88.   68.   49.]\n",
      " [  79.   94.   53.  108.]\n",
      " [ 102.   93.   73.   77.]\n",
      " [  95.   69.   61.   52.]\n",
      " [ 104.   80.   63.  107.]\n",
      " [ 123.   81.  112.  128.]\n",
      " [  82.   71.   96.   59.]\n",
      " [  98.  103.  109.   83.]\n",
      " [ 102.   87.   73.   77.]\n",
      " [ 101.  108.   79.  127.]\n",
      " [  88.   69.   61.   52.]\n",
      " [  62.   82.   71.  129.]\n",
      " [  80.   34.   89.   63.]\n",
      " [ 103.   92.  109.   72.]\n",
      " [ 105.  128.   83.   81.]\n",
      " [ 106.  124.  117.  110.]\n",
      " [ 108.   94.   79.  127.]\n",
      " [  87.   93.   73.   77.]\n",
      " [  98.  109.   92.   72.]\n",
      " [  89.  113.  107.  126.]\n",
      " [  99.  128.   83.   81.]\n",
      " [ 100.  124.  117.  110.]\n",
      " [  89.  104.  126.   34.]\n",
      " [ 101.   94.   79.  127.]\n",
      " [ 103.   98.   92.   83.]\n",
      " [ 117.  124.  100.  106.]\n",
      " [ 118.   33.    1.    5.]\n",
      " [ 125.   40.   98.  103.]\n",
      " [ 120.  104.   80.   89.]\n",
      " [ 127.  119.   79.   94.]\n",
      " [ 123.  128.   79.   81.]\n",
      " [ 122.  129.   59.   96.]\n",
      " [ 110.  124.  100.  106.]\n",
      " [ 111.    5.    1.   33.]\n",
      " [ 114.  127.   79.   94.]\n",
      " [ 113.   80.   89.  126.]\n",
      " [ 125.  112.   40.   98.]\n",
      " [ 116.  129.   59.   82.]\n",
      " [ 115.  128.   81.   79.]\n",
      " [ 110.  117.  100.  106.]\n",
      " [ 112.  121.   40.   98.]\n",
      " [  89.  107.  104.  120.]\n",
      " [ 114.   94.  119.   79.]\n",
      " [  99.  105.   81.   83.]\n",
      " [ 116.  122.   82.   59.]]\n"
     ]
    }
   ],
   "source": [
    "#measures distances between all images \n",
    "#this is being done to reduce number of duplicate faces\n",
    "num_test = dists.shape[0]\n",
    "y_pred = np.zeros((num_test,4))\n",
    "j=1\n",
    "for j in xrange(num_test):\n",
    "    dists[j][j]=1000\n",
    "    for k in range(0,4):\n",
    "        a=float(np.min(dists[j]))\n",
    "        b=float(np.argmin(dists[j]))\n",
    "        #print a,b\n",
    "        y_pred[j][k]=b;\n",
    "        dists[j][b]=1000;\n",
    "\n",
    "print y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stores the resulting data set in \"images\" directory to be tagged by user\n",
    "#using web interface\n",
    "#These tagged faces then used to train classifier\n",
    "#Note: First iteration of algorithm stores images in \"images2\" dir\n",
    "extras=[]\n",
    "done=[]\n",
    "count=0\n",
    "counter=0\n",
    "for i in range(0,len(y_pred)):\n",
    "    for j in y_pred[i]:\n",
    "        if ((count==0) and (j not in extras) and (j not in done)):\n",
    "            img=cv2.imread('faces/Testimg' +str(i)+'.png',0)\n",
    "            done.append(int(j))\n",
    "            #print j\n",
    "            cv2.imwrite('images2/Testimg'+str(counter)+'.png',img) \n",
    "            counter+=1\n",
    "            count=1\n",
    "            for m in y_pred[i]:\n",
    "                if m != j:\n",
    "                    extras.append(int(m))\n",
    "    count=0\n",
    "#print extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "total size of new array must be unchanged",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-91515cd9a395>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'images2/Testimg'\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.png'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0msimg3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0msimg3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'images2/Testimg'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.png'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msimg3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: total size of new array must be unchanged"
     ]
    }
   ],
   "source": [
    "num_files = sum(os.path.isfile(os.path.join('images2', f)) for f in os.listdir('images2'))\n",
    "print num_files\n",
    "t=[]\n",
    "for i in range(0,num_files-1):\n",
    "    img=cv2.imread('images2/Testimg' +str(i)+'.png',0)\n",
    "    simg3=cv2.resize(img,(50,50))\n",
    "    t.append(img.reshape(2500))\n",
    "    simg3=cv2.resize(img,(100,100))\n",
    "    cv2.imwrite('images2/Testimg'+str(i)+'.png',simg3)    \n",
    "print len(t)   \n",
    "data=np.array(t)\n",
    "print data.shape\n",
    "        \n",
    "fdata=np.float32(data)\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 1.0)\n",
    "ret,label,center=cv2.kmeans(fdata,34,None,criteria,20,cv2.KMEANS_RANDOM_CENTERS)\n",
    "for i in range(0,34):\n",
    "    print len(center),type(center)\n",
    "    print len(label),type(label)\n",
    "    print center[0].shape\n",
    "    imgc=np.uint8(center[i].reshape(50,50))\n",
    "    print type(ret),ret\n",
    "    cv2.imwrite('images/Testimg'+str(i+10)+'.png',center[i].reshape(50,50))\n",
    "#Stored unique faces in \"images\" dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=\"localhost\"\n",
    "webbrowser.get(\"C:/Program Files (x86)/Google/Chrome/Application/chrome.exe %s\").open(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    }
   ],
   "source": [
    "#import pdb\n",
    "#%pdb on\n",
    "classifier1=Classify()\n",
    "classifier1.trainsystem()\n",
    "#the classifier is being trained here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Video Capture For TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture('IMG_4100.MOV')\n",
    "face_cascade = cv2.CascadeClassifier('C:\\opencv\\sources\\data\\haarcascades\\haarcascade_frontalface_default.xml')\n",
    "print cap.grab()\n",
    "i=0\n",
    "j=0\n",
    "ret, frame = cap.read()\n",
    "while(ret):\n",
    "    # Capture frame-by-frame\n",
    "    #print j\n",
    "    ret, frame = cap.read()\n",
    "        # Our operations on the frame come here\n",
    "    if j%10==0:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.2, )\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "            cv2.imwrite('faces/Testimg'+str(i)+'.png',frame[y:y+h,x:x+w])\n",
    "            i=i+1\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame',frame)\n",
    "        j+=1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        j+=1\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n",
      "130\n",
      "(130L, 2500L)\n"
     ]
    }
   ],
   "source": [
    "num_files = sum(os.path.isfile(os.path.join('faces', f)) for f in os.listdir('faces'))\n",
    "print num_files\n",
    "t=[]\n",
    "for i in range(0,num_files-1):\n",
    "    img=cv2.imread('faces/Testimg' +str(i)+'.png',0)\n",
    "    simg3=cv2.resize(img,(50,50))\n",
    "    t.append(simg3.reshape(2500))\n",
    "    #simg3=cv2.resize(img,(100,100))\n",
    "    cv2.imwrite('faces/Testimg'+str(i)+'.png',simg3)    \n",
    "print len(t)   \n",
    "data=np.array(t)\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n"
     ]
    }
   ],
   "source": [
    "num_files = sum(os.path.isfile(os.path.join('faces', f)) for f in os.listdir('faces'))\n",
    "print num_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130L, 2500L)\n",
      "(130L, 2500L)\n",
      "[  50.3752064     0.           41.1193919    28.7832497    56.55263351\n",
      "   12.0489158    43.89272096   31.40106975   56.67878323   56.99790389\n",
      "   12.09283408   44.0579369    35.74567904   58.66778572   50.08937415\n",
      "   11.39528209   41.4377925    33.3734993    51.57564308   18.31699192\n",
      "   45.75014092   35.89032667   69.02419723   51.81013837   40.40430115\n",
      "   18.90811215   51.82007217   48.76528075   32.23888297   70.85495762\n",
      "   46.86977375   31.76763579   47.70053993   17.48990012   45.10315361\n",
      "   69.47566955   48.39918728   55.87745669   48.75337913   25.35036901\n",
      "   44.91870699   36.14779373   53.42412611   68.58149379   51.31196898\n",
      "   63.89966186   63.59077611   55.34892298   35.97847768   47.58497111\n",
      "   65.90758257   40.99816295   54.40752482   37.30682454   52.44397387\n",
      "   69.71261412   49.06685621   45.87501136   37.43200476   43.58311144\n",
      "   46.88114647   55.56294661   48.45652043   54.88464459   40.07642756\n",
      "   53.86983746   68.37302342   37.37018621   50.40681898   49.34629322\n",
      "   53.67966785   50.1053976    44.09578732   34.89718101   49.73709703\n",
      "   66.2348879    51.3258541    31.46411958   49.91915579   42.61140684\n",
      "   55.33152549   46.58578896   45.71677263   41.90392961   62.85499702\n",
      "   61.25138502   52.97526241   33.16203626   50.04514619   51.17095277\n",
      "   52.08162032   47.12991824   45.81823889   32.56357268   43.24918783\n",
      "   53.92222327   43.40291355   51.4148706    47.15559562   44.66988378\n",
      "   93.32407663   44.03450204   32.63266228   45.68657557   50.09308123\n",
      "   46.55627065   85.2035174    48.73071093   45.24396467   49.24247388\n",
      "  111.76835594   23.68262867   44.24327556   53.25685482   44.06767333\n",
      "   47.48153076   48.68285646  113.62506899   23.39518589   46.01957397\n",
      "   51.28382534   46.28759379   49.79974586   43.60934391   46.91838667\n",
      "  102.3021539    51.13789753   41.96104921   42.5548169    44.20594182]\n"
     ]
    }
   ],
   "source": [
    "#Applies HOG on all faces\n",
    "Train=[]\n",
    "Test=[]\n",
    "#hist=np.array(hist)\n",
    "for i in range(0,num_files-1):\n",
    "    image=cv2.imread('faces/Testimg' +str(i)+'.png',0)\n",
    "    fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualise=True)\n",
    "    hog_image=np.array(hog_image)\n",
    "    hog_image=hog_image.ravel()\n",
    "    Train.append(hog_image)\n",
    "    Test.append(hog_image)\n",
    "a=np.array(Train)\n",
    "b=np.array(Test)\n",
    "print a.shape\n",
    "print b.shape\n",
    "\n",
    "\n",
    "#for i in range(0,num_files-1):\n",
    "#    image=cv2.imread('UniqueFaces/Testimg' +str(i)+'.png',0)\n",
    "#    fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1), visualise=True)\n",
    "#    Test.append(hog_image[:])   \n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "dists=cdist(Test,Train)\n",
    "print dists[1]\n",
    "if num_files>=175:\n",
    "    k=12\n",
    "else:\n",
    "    k=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  23.   14.   18.   30.]\n",
      " [  15.    5.   10.   33.]\n",
      " [  11.   16.    6.   20.]\n",
      " [   7.   17.  102.   87.]\n",
      " [   9.   18.   14.   57.]\n",
      " [  10.    1.   15.   19.]\n",
      " [  16.    2.   20.   11.]\n",
      " [  17.   12.   28.    3.]\n",
      " [  13.   22.   84.   29.]\n",
      " [   4.   14.   18.   57.]\n",
      " [   5.   15.    1.   25.]\n",
      " [   2.   20.    6.   16.]\n",
      " [  17.    7.   28.   21.]\n",
      " [  84.    8.   22.   29.]\n",
      " [  30.   60.   57.    0.]\n",
      " [  10.    1.   19.    5.]\n",
      " [   6.    2.   20.   11.]\n",
      " [  12.    7.   28.   77.]\n",
      " [  23.   14.   57.    0.]\n",
      " [  15.   25.   10.    1.]\n",
      " [  11.   16.    6.    2.]\n",
      " [  28.   17.   87.  102.]\n",
      " [  29.   35.   84.   13.]\n",
      " [  18.    0.   57.   14.]\n",
      " [  58.   83.   92.  103.]\n",
      " [  19.   15.   10.    1.]\n",
      " [  97.   80.  120.   70.]\n",
      " [  20.   76.   32.   11.]\n",
      " [  77.   17.   31.    7.]\n",
      " [  22.   35.   84.   43.]\n",
      " [  14.   57.   60.   36.]\n",
      " [  77.   28.   87.   41.]\n",
      " [  74.   42.   56.   27.]\n",
      " [   1.   15.   39.   19.]\n",
      " [  97.   38.   89.   80.]\n",
      " [  43.   66.   75.   29.]\n",
      " [  57.   30.   60.   23.]\n",
      " [  61.   52.   69.   78.]\n",
      " [  54.   34.   97.   63.]\n",
      " [  25.   33.   19.   15.]\n",
      " [ 112.   98.  103.   92.]\n",
      " [  51.   67.   31.   77.]\n",
      " [  56.   32.   65.   76.]\n",
      " [  66.   35.   55.   75.]\n",
      " [  36.   57.   68.   16.]\n",
      " [  42.   56.   65.   76.]\n",
      " [  52.   37.   61.   88.]\n",
      " [  54.   70.   38.   63.]\n",
      " [  53.   64.   83.   72.]\n",
      " [  51.   41.   67.   73.]\n",
      " [  66.   55.   43.   35.]\n",
      " [  41.   67.   73.   87.]\n",
      " [  37.   61.   69.   88.]\n",
      " [  48.   64.   83.   72.]\n",
      " [  38.   63.   97.   34.]\n",
      " [  66.   43.   35.   75.]\n",
      " [  42.   76.   74.   32.]\n",
      " [  60.   30.   36.   14.]\n",
      " [  24.   83.   64.   72.]\n",
      " [  81.   71.  129.   96.]\n",
      " [  57.   30.   14.   36.]\n",
      " [  37.   69.   52.   88.]\n",
      " [  71.   96.   81.  129.]\n",
      " [  89.   54.   80.   97.]\n",
      " [  83.   72.   53.   48.]\n",
      " [  42.   32.   56.   76.]\n",
      " [  55.   43.   35.   75.]\n",
      " [  73.   87.   51.   41.]\n",
      " [  60.   57.   36.   30.]\n",
      " [  61.   37.   88.   52.]\n",
      " [  97.   54.   26.   47.]\n",
      " [  81.   62.   91.   59.]\n",
      " [  83.  103.   98.   92.]\n",
      " [  87.   67.  102.   93.]\n",
      " [  32.   56.   76.   42.]\n",
      " [  66.   43.   35.   55.]\n",
      " [  56.   74.   27.   32.]\n",
      " [  31.   87.   28.   93.]\n",
      " [  37.   69.   61.   88.]\n",
      " [  94.  101.  127.  108.]\n",
      " [  89.   97.  120.   63.]\n",
      " [  71.   91.   59.   96.]\n",
      " [ 128.   99.  105.   83.]\n",
      " [  72.   92.   64.  103.]\n",
      " [  13.   29.   75.   55.]\n",
      " [  44.   88.   68.   49.]\n",
      " [  79.   94.   53.  108.]\n",
      " [ 102.   93.   73.   77.]\n",
      " [  95.   69.   61.   52.]\n",
      " [ 104.   80.   63.  107.]\n",
      " [ 123.   82.  112.  128.]\n",
      " [  81.   71.   96.   59.]\n",
      " [  98.  103.  109.   83.]\n",
      " [ 102.   87.   73.   77.]\n",
      " [ 101.  108.   79.  127.]\n",
      " [  88.   69.   61.   52.]\n",
      " [  62.   81.   71.  129.]\n",
      " [  80.   34.   89.   63.]\n",
      " [ 103.   92.  109.   72.]\n",
      " [ 105.  128.   83.   82.]\n",
      " [ 106.  125.  117.  110.]\n",
      " [ 108.   94.   79.  127.]\n",
      " [  87.   93.   73.   77.]\n",
      " [  98.  109.   92.   72.]\n",
      " [  89.  113.  107.  126.]\n",
      " [  99.  128.   83.   82.]\n",
      " [ 100.  125.  117.  110.]\n",
      " [  89.  104.  126.   34.]\n",
      " [ 101.   94.   79.  127.]\n",
      " [ 103.   98.   92.   83.]\n",
      " [ 117.  125.  100.  106.]\n",
      " [ 118.   33.    1.    5.]\n",
      " [ 124.   40.   98.  103.]\n",
      " [ 120.  104.   80.   89.]\n",
      " [ 127.  119.   79.   94.]\n",
      " [ 123.  128.   79.   82.]\n",
      " [ 122.  129.   59.   96.]\n",
      " [ 110.  125.  100.  106.]\n",
      " [ 111.    5.    1.   33.]\n",
      " [ 114.  127.   79.   94.]\n",
      " [ 113.   80.   89.  126.]\n",
      " [ 124.  112.   40.   98.]\n",
      " [ 116.  129.   59.   81.]\n",
      " [ 115.  128.   82.   79.]\n",
      " [ 112.  121.   40.   98.]\n",
      " [ 110.  117.  100.  106.]\n",
      " [  89.  107.  104.  120.]\n",
      " [ 114.   94.  119.   79.]\n",
      " [  99.  105.   82.   83.]\n",
      " [ 116.  122.   81.   59.]]\n"
     ]
    }
   ],
   "source": [
    "#measures distances between all images \n",
    "#this is being done to reduce number of duplicate faces\n",
    "num_test = dists.shape[0]\n",
    "y_pred = np.zeros((num_test,4))\n",
    "j=1\n",
    "for j in xrange(num_test):\n",
    "    dists[j][j]=1000\n",
    "    for k in range(0,4):\n",
    "        a=float(np.min(dists[j]))\n",
    "        b=float(np.argmin(dists[j]))\n",
    "        #print a,b\n",
    "        y_pred[j][k]=b;\n",
    "        dists[j][b]=1000;\n",
    "\n",
    "print y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stores the resulting data set in \"TestData\" directory to used by our classifier\n",
    "#For testing purposes\n",
    "extras=[]\n",
    "done=[]\n",
    "count=0\n",
    "counter=0\n",
    "for i in range(0,len(y_pred)):\n",
    "    for j in y_pred[i]:\n",
    "        if ((count==0) and (j not in extras) and (j not in done)):\n",
    "            img=cv2.imread('faces/Testimg' +str(i)+'.png',0)\n",
    "            done.append(int(j))\n",
    "            #print j\n",
    "            cv2.imwrite('images2/Testimg'+str(counter)+'.png',img) \n",
    "            counter+=1\n",
    "            count=1\n",
    "            for m in y_pred[i]:\n",
    "                if m != j:\n",
    "                    extras.append(int(m))\n",
    "    count=0\n",
    "#print extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "63\n",
      "(63L, 2500L)\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n",
      "34 <type 'numpy.ndarray'>\n",
      "63 <type 'numpy.ndarray'>\n",
      "(2500L,)\n",
      "<type 'float'> 11003596.9297\n"
     ]
    }
   ],
   "source": [
    "num_files = sum(os.path.isfile(os.path.join('images2', f)) for f in os.listdir('images2'))\n",
    "print num_files\n",
    "t=[]\n",
    "for i in range(0,num_files-1):\n",
    "    img=cv2.imread('images2/Testimg' +str(i)+'.png',0)\n",
    "    simg3=cv2.resize(img,(50,50))\n",
    "    t.append(img.reshape(2500))\n",
    "    simg3=cv2.resize(img,(100,100))\n",
    "    cv2.imwrite('images2/Testimg'+str(i)+'.png',simg3)    \n",
    "print len(t)   \n",
    "data=np.array(t)\n",
    "print data.shape\n",
    "        \n",
    "fdata=np.float32(data)\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 1.0)\n",
    "ret,label,center=cv2.kmeans(fdata,34,None,criteria,20,cv2.KMEANS_RANDOM_CENTERS)\n",
    "for i in range(0,34):\n",
    "    print len(center),type(center)\n",
    "    print len(label),type(label)\n",
    "    print center[0].shape\n",
    "    imgc=np.uint8(center[i].reshape(50,50))\n",
    "    print type(ret),ret\n",
    "    cv2.imwrite('TestData/Testimg'+str(i)+'.png',center[i].reshape(50,50))\n",
    "#Stored unique faces in \"images\" dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "niazi\n",
      "\n",
      "saad\n",
      "\n",
      "niazi\n",
      "\n",
      "sheri\n",
      "\n",
      "sheri\n",
      "\n",
      "sheri\n",
      "\n",
      "usama\n",
      "\n",
      "arslan\n",
      "\n",
      "sheri\n",
      "\n",
      "sufyan\n",
      "\n",
      "ahsan\n",
      "\n",
      "niazi\n",
      "\n",
      "sheri\n",
      "\n",
      "arslan\n",
      "\n",
      "mohsin\n",
      "\n",
      "sheri\n",
      "\n",
      "saad\n",
      "\n",
      "rajabilal\n",
      "\n",
      "mohsin\n",
      "\n",
      "mohsin\n",
      "\n",
      "sheri\n",
      "\n",
      "arslan\n",
      "\n",
      "saad\n",
      "\n",
      "sufyan\n",
      "\n",
      "hamza\n",
      "\n",
      "sheri\n",
      "\n",
      "ahsan\n",
      "\n",
      "saad\n",
      "\n",
      "ali\n",
      "\n",
      "sheri\n",
      "\n",
      "saad\n",
      "\n",
      "kahoot\n",
      "\n",
      "arslan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier1.predict('TestData')\n",
    "#Predicting attendance here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
